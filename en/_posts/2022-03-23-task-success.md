---
altLangPage: "/2022/03/23/reussite-des-taches"
date: 2022-03-23
description: "Evidence from the GC Task Success Survey can help support positive cultural change within your organization."
title: "Using task success data to improve user experience"
---

The Treasury Board of Canada Secretariat and the Principal Publisher are working together with departments and agencies to use a **task success survey** to measure the performance of web content and services. The survey collects direct user feedback that departments can use **to improve the performance of top task content**.

Invitations to participate in the GC Task Success Survey began appearing on Canada.ca in January 2021. About 1 of every 10 visitors receives the invitation to provide feedback on their experience. If they agree, the survey asks them to:

- identify the task that they came to complete 
- indicate if they could complete their task
- rate their experience in terms of ease of use and satisfaction 
- include feedback in their own words

[GC Task Success Survey](https://design.canada.ca/continuous-improvement/monitoring/GCTSS.html)

## Using feedback to uncover issues 

> “[User] feedback is a critical input into ensuring that services meet the needs of [users] and to support continual improvement” - [Guideline on Service and Digital](https://www.canada.ca/en/government/system/digital-government/guideline-service-digital.html#ToC2_2)
>

How can this type of survey help you improve your web presence?

Firstly, the task success survey runs continually. This means you can track performance over time. The results can help you identify straightforward issues that you can improve with minimal effort. Solving these lets your team build skills in analyzing and acting on feedback. 

You may discover **common issues** like:

- questions that have no clear answers
- missing information
- confusing instructions
- unclear navigation
- things that don’t work (links, form submissions, web applications)
- policy gaps 
- reactions to policy changes
- needs and situations that existing programs aren’t addressing 

Collecting feedback this way can also highlight **changes in success rates**. 

These changes may be a result of specific changes in your content, in policy or even in the public environment. Being able to tie fluctuations to a specific time frame can help you figure out how to resolve issues early, before they affect a large portion of your user base. It also means you can see positive fluctuations when you fix something. 

As you work through fixing the smaller, more manageable issues, look at the survey data again. Have you stopped seeing messages about that particular issue? 

For more complex content issues, you may need extra research, tools, and collaboration, but the survey results still give you a solid starting point. 

**Share successes** with leaders. This will:

- show the value of gathering the survey data and feedback
- illustrate how it can be used to improve performance
- increase interest and support for tackling some of the more complex issues

## Supporting cultural change

Evidence from the GC Task Success Survey can also help support positive cultural change within your organization. 

Having the feedback at your fingertips means your team can begin to shift from an expertise- and assumptions-based model of web content delivery to one that is more responsive and keenly tuned into people’s needs. It is an early but important step towards adopting more advanced processes and research methods.

<table class="table table bordered">
    <caption>Web content delivery models</caption>
    <thead>
        <tr>
            <th>Expertise-based model</th>
            <th>Evidence-based model</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Improving tasks as time allows</td>
            <td>Making time for top task improvement work</td>
        </tr>
        <tr>
            <td>Making assumptions based on experience</td>
            <td>Asking questions and doing research</td>
        </tr>
        <tr>
            <td>Reliance on best practices to frame decision making</td>
            <td>Grounding decisions in evidence, including user feedback</td>
        </tr>
        <tr>
            <td>Reporting focused on volumetrics (we had X many visitors)</td>
            <td>Reporting focused on outcomes (this X percent of visitors successfully reached the final step)</td>
        </tr>
        <tr>
            <td>Improving a task based on a single team’s scope of responsibility</td>
            <td>Having multidisciplinary teams work together to improve a task</td>
        </tr>
    </tbody>
</table>


## Task success is a team sport 

Advocating for change on behalf of users is a team sport. It begins with understanding the problem and often requires the knowledge, skills and expertise of several disciplines to solve it.

Many teams don’t have dedicated product or service managers. The responsibility of reading user feedback or doing detailed analysis with survey results may fall on the person normally responsible for reporting on web analytics. This can actually be beneficial as analysis requires consistent attention to identify and watch for shifts in patterns (so this responsibility shouldn’t change between team members too often).

However, while one person may take the lead for reporting on survey results, everyone in a task’s ecosystem can and should participate in fixing or improving it. 

This includes the typical digital roles like designers, developers and user researchers. But it should also include: 

- service or product owners
- program or policy experts
- strategic communicators
- e-communications advisors
- senior managers

Whatever your position, you can ask about result trends, pose specific research questions for deeper analysis, or review the feedback yourself. 

When everyone gets involved in understanding pain points and making improvements, the culture changes to be more service oriented, and the people using the content benefit. 

## Get feedback, take action, repeat

Collecting feedback isn’t enough. You must be prepared to take action. 

In an environment of competing priorities, it can be difficult to make a case for shifting certain demands in favour of updating web content that is already “approved” and “live.” 

Some may feel inclined to ask, “With limited resources, why revisit something that’s already ‘made it out the door?’”

Getting something published online isn’t the end - it’s the beginning. Once it’s “out the door,” a cycle of continuous improvement begins. The beauty of the web is that it’s easy to make improvements as things change.

The task success survey gives you access to data and feedback from the people that use your services. They’ve taken the time to tell you that they failed or got frustrated. Their words can help you build a compelling case for dedicating precious resources to making needed improvements. It’s important to remember that the end goal of any program or service is not for the government to successfully communicate about it. **The goal is for the people who use the program or service to be successful.**                 

## Final word

Everyone in a task’s ecosystem has a role to play. Teams need to work together to: 

- **create space** for improving top tasks 
- regularly **review and/or share the issues** identified in the survey feedback with content and policy owners
- **support user research and design activities** to address task issues and iteratively build skills

By regularly demonstrating success solving smaller issues, you will build momentum, gain in-house skills, hone processes, and gain trust for dedicating resources to solving larger, more complex problems. 

## Learn more

- [Continuous improvement process](https://design.canada.ca/continuous-improvement.html)

- [Improve digital services by measuring outcomes](https://blog.canada.ca/2018/02/23/Improve-digital-services-measuring-outcomes)